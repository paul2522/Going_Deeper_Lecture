{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backbone Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습 목표"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 딥러닝 논문의 구조에 익숙해지기\n",
    "* 네트워크를 구조화하는 여러 방법의 발전 양상을 알아보기\n",
    "* 새로운 논문 찾아보기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습 내용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 딥러닝 논문의 구조\n",
    "* ResNet의 핵심 개념과 그 효과\n",
    "* ResNet 이후 시도 (1) Connection을 촘촘히\n",
    "* ResNet 이후 시도 (2) 어떤 특성이 중요할까?\n",
    "* 모델 최적화하기 (1) Neural Architecture Search\n",
    "* 모델 최적화하기 (2) EfficientNet\n",
    "* 직접 찾아보기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Deep Residual Learning for Image Recognition(paper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voca"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Abstract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* expliciitly : 명쾌하게, 명백히\n",
    "* reformulate : 새로 만들다.\n",
    "* residual : 잔여의, 잔류\n",
    "* substantially : 상당히, 많이, 주로, 대체로\n",
    "* comprehensive : 포괄적인\n",
    "* empirical : 경험에 근거한, 실증적인\n",
    "* solely : 오로지, 단독으로\n",
    "* due to : 때문에\n",
    "* COCO : large-scale object detection, segmentation, and captioning dataset\n",
    "* foundation : 기초, 토대"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* end to end : 끝과 끝을 붙여\n",
    "* enrich : 질을 높이다, 부유하게 하다.\n",
    "* crucial : 중대한, 결정적인\n",
    "* exploit : 이용하다, 착취하다, 위업, 공적(부당한 늬앙스)\n",
    "* nontrivial : 사소하지 않은, 적지않은\n",
    "* notorious : 악명 높은\n",
    "* hamper : 방해하다\n",
    "* convergence : 수렴\n",
    "* address by : (문제에 대해) 다루다, 고심하다\n",
    "* intermediate : 중간의, 중급의\n",
    "* throughly : 완전히, 대단히,\n",
    "* identity mapping : 항등 맵핑\n",
    "* underlying : 기저의, 깔리는, 기본\n",
    "* denote : 나타내다.\n",
    "* realized by : ~로 실현되다.\n",
    "* exhibit : 드러내다\n",
    "* inhibit : 억제하다\n",
    "* akin to : 유사한\n",
    "* generic : 포괄적인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Related Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Partial Differential Equations (PDEs) : 편미분방정식\n",
    "* responsible : 책임지고 있는, 원인이 되는\n",
    "* responsible for  : 책임이 있는, 원인이 있는\n",
    "* hierarchical : 계층적\n",
    "* auxiliary : 보조의, 예비의"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deep Residual Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* asymptotically : 점근적으로\n",
    "* counterintuitive : 반직관적인\n",
    "* precondition : 전제 조건\n",
    "* perturbations : 섭동"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 정리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Abstract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 우리는 VGG보다 깊이는 증가시키되 복잡도는 덜한 모델인 Deep residual net을 만들었습니다.\n",
    "* ResNet은 기존의 모델보다 더 쉽게 최적화가 가능하며 더 좋은 정확도를 가지고 있으며 이를 증명할 수 있습니다.\n",
    "* 또한 2015년 분류대회에서 1위의 성적을 거두었습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* CV 분류문제에서 깊이는 매우 중요했으며 매우 깊은 모델들이 대부분 큰 효율을 보이거나 영향을 크게 줬습니다.\n",
    "* 그로인해 생긴 질문이 더 나은 네트워크를 배우는 것이 더 많은 layer를 쌓는 것 만큼 쉬운가?\n",
    "* 해당 질문에 대한 장애물은 vanishing/exploding gradient 이고 이것은 처음부터 수렴을 방해하는 것 입니다.\n",
    "* 하지만 해당 어려움은 정규화된 초기화나 중간에 있는 정규화 레이어에서 많이 다뤄집니다.\n",
    "* 이런 정규화되는 초기화나 정규화 레이어는 다수의 레이어의 네트워크가 SGD(stochastic gradient descent) 와 back propagation 을 위한 수렴을 시작하는 것을 가능하게 합니다.\n",
    "* 깊은 네트워크가 수렴을 시작할때, degradation 문제점이 발생\n",
    "* degradation 문제점 : 깊이가 증가하면 정확도가 포화되다가 급속도로 떨어지는 문제\n",
    "* degradation 문제는 overfitting 때문이 아니다.\n",
    "* 적절한 깊이의 모델에 추가로 레이어를 넣으면 높은 traing error가 발생한다.\n",
    "* Fig1 을 통해 증명됨.\n",
    "* 이를 통해 모든 시스템이 쉽게 최적화되지 않음을 알 수 있다.\n",
    "* 깊은 모델을 만들 때, 얕은 모델에서 identity mapping layer 이나 학습된 얕은 모델의 복사된 다른 레이어들을 추가함으로써 degradation 문제를 예방할 수 있다.\n",
    "* 이 방법을 통해 깊은 모델은 더 높은 training error를 발생시키지 않는다.\n",
    "* 이 논문에서 degradation 문제를 deep residual learning framework로 다룹니다.\n",
    "* 몇개의 쌓인 레이어들로 직접적으로 원하는 매핑으로 맞추기보단 이러한 레이어들이 residual mapping에 맞추기를 바란다.\n",
    "* 우리가 원하는 기본 매핑을 $H(x)$라 할 때\n",
    "* 쌓인 비선형적 레이어들은 $F(x) := H(x) - x.$를 매핑한다.\n",
    "* 여기서 residual mapping이 다른 관계없는 mapping보다 더 쉽게 최적화가 가능하다고 가설을 세운다.\n",
    "* 극단적으로, 항등 매핑이 최적이라면, 잔차를 0으로 만드는 것이 쌓인 비선형적 레이어로 항등 매핑을 적합하는 것보다 쉬울 것이다.\n",
    "* $F(x) + x$ 의 형태는 feedforward 뉴런 네트워크와 shortcut connections로 실현될 수 있다.(Fig. 2)\n",
    "* Shortcut connection : 몇개의 layer를 건너뛰는 것\n",
    "* 여기의 경우, shortcut connection은 항등 매핑을 수행한다. 그리고 그 결과는 스택된 레이어의 결과에 더해진다.($x + F(x)$)\n",
    "* 항등 shortcut connections 은 추가 파라미터를 더하지도 않고 계산 복잡도 증가시키지 않는다.\n",
    "* 전체 네트워크는 역전파와 SGD로 끝에서 끝으로 훈련될 수 있다.\n",
    "* ImageNet을 통해 실험하면서 2가지를 보여준다.\n",
    "* 1. Deep residual nets는 쉽게 최적화되며 반대의 보통 net은 깊이가 깊어질수록 더 높은 training error를 나타낸다.\n",
    "* 2. Deep residual nets는 깊이를 크게 증가시키면 쉽게 정확도 증가를 얻는다, 이전의 네트워크들보다 확실히 더 좋은 결과를 생성하면서.\\\n",
    "* CIFAR-10에서도 비슷한 현상을 보임.\n",
    "* 152 layer residual net은 ImageNet에서 나온 가장 깊은 네트워크였다, 하지만 VGG보다 더 낮은 복잡도.\n",
    "* 우리 앙상블은 3.57%의 top-5 error가 나와서 1등했다.\n",
    "* 이런 깊은 표현은 분류뿐 아니라 다른 작업에도 큰 효율을 보였다.\n",
    "* 이런걸로 보아 우리 모델은 포괄적이다. vision 말고도 다른 문제에도 쓰일 것으로 예상됨."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Related Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Residual Representations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* VLAD : 사전과 관련해서 잔여 벡터로 인코딩하는 표현\n",
    "* Fisher Vector : VLAD가 확률론적 버전으로 구성된 것\n",
    "* image retrieval (상품 검색) : 이미지를 넣어서 유사한 이미지를 출력\n",
    "* 둘다 이미지 검색과 분류에 강한 얕은 표현이다.\n",
    "* 낮은 레벨의 비전과 컴퓨터 그래픽에서 편미분 방정식을 풀기 위해 Multigrid method를 사용해서 시스템을 여러 크기의 작은 문제들로 재구성함.\n",
    "* 이 작은 문제들은 거칠거나 미세한 크기에 따른 residual solution에 대한 원인이 있습니다.\n",
    "* Multigrid의 대안은 계층적 기반 사전 조건화(hierarchical basis preconditioning)입니다.\n",
    "* 2개의 크기 사이에서 residual vectors를 표현하는 변수에 의존합니다.\n",
    "* 이러한 해결책들은 기존의 방법보다 더 빠르게 수렴하게 합니다.\n",
    "* 기존의 방법은 잔류에 대한 특성을 알지 못합니다.\n",
    "* 이렇게 해서 최적화를 좀 더 간단히 해줍니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Shortcut Connections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* MLP(Multi-Layer Perceptrons)를 훈련하는 초기 연구 중 하나는 네트워크 입력과 출력을 이어주는 선형 레이어를 추가하는 것이다.[34,49]\n",
    "* 다른 연구에서는 몇개의 중간 레이어가 보조 분류기로 연결되어 vanishing/exploding gradient 문제를 다룬다.[44,24]\n",
    "* 또 다른 연구에서는 shortcut connections을 구축하여 layer 반응, 기울기, 전파 오류들을 집중시켰다.[39,38,31,47]\n",
    "* [44]논문에서는 inception layer가 shortcut branch와 몇개의 깊은 branch로 구성되었다.\n",
    "* 여기 연구와 동시에, \"highway networks\"가 gating 기능을 가지는 shortcut connections 을 발표했다.\n",
    "* 해당 gate는 데이터-의존적이고 매개변수를 가진다, 반면 여기 항등 shortcut은 파라미터가 없다.\n",
    "* gate가 0으로 가까워질 때, highway networks는 non-residual 함수를 표현, 반면 본인들은 항상 residual 함수들을 배움\n",
    "* 또한 항등 shortcut은 절때 0으로 가까워지지 않고 모든 정보들이 전달되고 추가된 residual 함수들이 학습함.\n",
    "* 게다가 highway networks 는 깊이를 엄청 증가시켜도 정확도 증가를 보이지 않는다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Deep Residual learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.1. Residual Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 스택 레이어들이 $H(x)$로 매핑보단 $F(x) := H(x) - x$로 매핑되게 하는게 좋다.\n",
    "* 항등 매핑이 적절한 preconditioning을 제공한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.2. Identity Mapping by Shortcuts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ...\n",
    "* "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
